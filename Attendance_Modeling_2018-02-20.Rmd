---
title: "Attendance Analysis and Modeling"
author: "Steph Oliva and Chris Haid"
resource_files:
- kipp-chicago-silo-2-aa786970aefd.json
- kipp-chicago-silo-2-aa786970aefd.json
- kipp-chicago-silo-2-aa786970aefd.json
- kipp-chicago-silo-2-aa786970aefd.json
output:
  html_document:
    df_print: paged
    fig_width: 10
    toc: yes
    toc_float: yes
---
## Motivation

This is a first pass at modeling student-level attendence.  The primary use cases are:

  * to provide predictions of end-of-year average daily attendance (ADA) by for each student earlier in the year (say the middle of the 1st quarter).
  * to provide predictions of end-of-year aveage daily attendance (ADA) by for each school and at the school level earlier in the year (say the middle of the 1st quarter).
  * Prepare for the addition of an On-Track metric in SQRP. 

Another goal is gain familiarity with the [tidymodels](https://github.com/tidymodels) suite of packages (e.g, `recipes`, `parsnip`, `resample`)


The details on pacakges and data we pull are left to the appendix. 

```{r packages, include = FALSE}
library(tidyverse)
library(silounloadr)
library(kippcolors)
library(janitor)
library(lubridate)
library(caret)
library(broom)
library(modelr)
library(tidymodels)
library(kknn)
library(VGAM)
#library(prophet)
library(greta)
library(bayesplot)
library(rstanarm)
theme_set(theme_kipp_light())


bigrquery::set_service_token("kipp-chicago-silo-2-aa786970aefd.json")

```

```{r knitr_options, results='hide', echo=FALSE}
knitr::opts_knit$set(comment = FALSE,
                     warning = FALSE, 
                     progress = FALSE, 
                     verbose = FALSE#, 
                     #width = "90%"
                     )
```


```{r att_mem_tables, cache=TRUE, results='hide', echo=FALSE}
membership <- get_powerschool("ps_membership_reg") %>% 
  select(studentid,
         schoolid,
         date = calendardate,
         enrolled = studentmembership,
         grade_level,
         attendance = ATT_CalcCntPresentAbsent,
         yearid) %>%
  filter(yearid >= 25)


attendance <- get_powerschool("attendance") %>% 
  filter(yearid >= 25,
        att_mode_code == "ATT_ModeDaily") 

attendance_code <- get_powerschool("attendance_code") %>%
  mutate(att_code = if_else(att_code == "true", "T", att_code)) %>% 
  select(attendance_codeid = id,
         att_code)
  
  
```


```{r students, cache=TRUE, include=FALSE}
students <- get_powerschool("students") %>% 
  select(studentid = id, 
         student_number,
         gender,
         entrydate,
         schoolentrydate,
         districtentrydate,
         geocode) %>%
  collect()
  
```


```{r joining_tables, results='hide', echo=FALSE, cache=TRUE}
member_att <- membership %>% 
  dplyr::left_join(attendance %>% 
              select(-schoolid,
                        -yearid) %>% 
              dplyr::left_join(attendance_code,
                        by = "attendance_codeid"),
            by = c("studentid",
                   "date" = "att_date")) %>% 
  collect()

```

```{r recoding, results='hide', echo=FALSE}
member_att %>% 
  janitor::tabyl(att_code)

student_att <- member_att %>%
  mutate(enrolled0 = 1,
         enrolled = if_else(att_code == "D" & !is.na(att_code), 0, enrolled0),
         present0 = ifelse(is.na(att_code), 1, 0),
         present1 = ifelse(att_code %in%  c("A", "S"), 0, present0),
         present2 = ifelse(att_code == "H", 0.5, present1),
         present3 = ifelse(att_code %in% c("T", "E", "I"), 1, present2),
         present = ifelse(is.na(present2), 1, present3),
         absent = (1 - present)*enrolled,
         tardy = ifelse(att_code %in% "T", 1, 0),
         dna0 = if_else(att_code == "D", 1, 0),
         dna = if_else(is.na(dna0), 0, dna0)) %>%
  select(yearid,
         schoolid,
         studentid,
         grade_level,
         date,
         att_code,
         enrolled,
         present,
         absent,
         tardy,
         dna)


```




## Quantities of interest
Now we calculate some quantities of interest: 

* year_end ADA, 
* cumulative ADA by date

```{r cumulative quantities of interest}
yearly_ada <- student_att %>% 
  filter(yearid < 28) %>%
  group_by(yearid,
           studentid) %>% 
  summarize(enrolled = sum(enrolled),
            absent = sum(absent),
            year_end = 1 - (absent/enrolled))
 
cum_ada <- student_att %>% 
  filter(yearid < 28) %>%
  group_by(yearid,
           studentid) %>% 
  arrange(date) %>% 
  mutate(cum_enrolled = cumsum(enrolled),
         cum_absent = cumsum(absent),
         running_ada = 1 - (cum_absent/cum_enrolled)) %>% 
  filter(cum_enrolled > 0)

yearly_cum_ada <- cum_ada %>% 
  select(yearid,
         schoolid,
         grade_level,
         studentid,
         date,
         cum_enrolled,
         cum_absent,
         running_ada) %>% 
  dplyr::left_join(yearly_ada %>% 
              select(-c(enrolled,
                        absent)),
            by = c("yearid",
                   "studentid"))


```

Now we begin doing some subsetting to build a basic model. We'll pull the data for each student over the last few years (excluding SY 18-19) for the last school day in December.  We'll build our model off of this "snapshot". The resulting table shows for each student their number of days enrolled (`cum_enrolled`), days absent (`cum_absent`), ADA through last school day in December (`running_ada`), and the given year's EOY ADA (`year_end`).

### A snapshot in December
```{r dec_subset}
year_end_date <- yearly_cum_ada %>% 
  group_by(yearid) %>% 
  select(date) %>% 
  distinct() %>% 
  filter(date == max(date))

dec_dates <- yearly_cum_ada %>% 
  group_by(yearid) %>% 
  select(date) %>% 
  distinct() %>% 
  filter(lubridate::month(date) == 12) %>% 
  filter(date == max(date))

yca_filtered_dec <- yearly_cum_ada %>% 
  inner_join(dec_dates %>% 
               ungroup() %>% 
               select(-yearid),
             by = c("date")) %>%
  ungroup() %>%
  mutate(yearid = as.factor(yearid),
         schoolid = as.factor(schoolid))

yca_filtered_yr_end <- yearly_cum_ada %>% 
  inner_join(year_end_date %>% 
               ungroup() %>% 
               select(-yearid),
             by = c("date")) %>%
  ungroup() %>%
  mutate(yearid = as.factor(yearid),
         schoolid = as.factor(schoolid)) %>% 
  select(yearid,
         schoolid,
         studentid,
         yr_end_enrolled = cum_enrolled,
         yr_end_absent = cum_absent)

yca_filtered <- yca_filtered_dec %>% 
  inner_join(yca_filtered_yr_end,
             by = c("yearid",
                    "schoolid",
                    "studentid")) %>% 
  mutate(yr_end_present = yr_end_enrolled - yr_end_absent,
         cum_present = cum_enrolled - cum_absent)

yca_filtered %>%
  ggplot(aes(x = running_ada , y = year_end, color = schoolid)) +
  geom_hline(aes(yintercept = .9)) +
  geom_point(alpha = .7) +
  geom_smooth(se = FALSE) +
  scale_color_kipp() +
  labs(y = "ADA (year end)",
       x = "ADA (last school day in December)",
       color = "School ID #")
```
## Initial Models 

### Linear Mdoel
Our first model (`mod_0`) models year end ADA as a function of cumulative days enrolled and cumulative days absent through the last day of December, using school year as a fixed effect:

$$ y_{i} = f(\alpha + \beta_{e}d_{e} + \beta_{a}d_{a} +\delta_{year} ) $$

We'll first fit a linear model:
```{r lm}

formula_0 <- as.formula(year_end ~ cum_enrolled + cum_absent + yearid)

mod_0 <- lm(formula = formula_0, 
            data = yca_filtered)

summary(mod_0)

  
```
Let's plot the ranked residuals of `mod_0`
```{r plot_residuals_lm}
# yca_filtered %>% 
#   ungroup() %>% 
#   modelr::add_predictions(mod_0) %>% 
#   modelr::add_residuals(mod_0) %>% 
#   arrange(resid) %>% 
#   group_by(yearid) %>% 
#   mutate(rank = row_number(resid)) %>% 
#   ggplot(aes(x = rank, y = resid)) +
#   geom_segment(aes(xend = rank, yend = 0),
#                size = .075, alph=.3) +
#   facet_grid(yearid~.)


plot_ranked_residuals <- function(data,model){
data %>% 
  modelr::add_predictions(model) %>% 
  modelr::add_residuals(model) %>% 
  arrange(resid) %>% 
  group_by(yearid) %>% 
  mutate(rank = row_number(resid)) %>% 
  ggplot(aes(x = rank, y = resid)) +
  geom_segment(aes(xend = rank, yend = 0),
               size = .075, alpha =  .3) +
  facet_grid(yearid~.)

    
}

plot_ranked_residuals(yca_filtered, mod_0)

```
And here are the residuals as a function of actuals. 
```{r}
# yca_filtered %>% 
#   ungroup() %>% 
#   modelr::add_predictions(mod_0) %>% 
#   modelr::add_residuals(mod_0) %>% 
#   arrange(resid) %>% 
#   group_by(yearid) %>% 
#   mutate(rank = row_number(resid)) %>% 
#   ggplot(aes(x = year_end, y = resid)) +
#   geom_point(aes(color = cum_enrolled),
#              size = .001) +
#   scale_color_kipp(discrete = FALSE) +
#   facet_grid(yearid ~.)

plot_pred_v_residuals <- function(data, model){
  data %>% 
  ungroup() %>% 
  modelr::add_predictions(model) %>% 
  modelr::add_residuals(model) %>% 
  arrange(resid) %>% 
  group_by(yearid) %>% 
  mutate(rank = row_number(resid)) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(aes(color = cum_enrolled),
             size = .001) +
  scale_color_kipp(discrete = FALSE) +
  facet_grid(yearid ~.)
}
  

plot_pred_v_residuals(yca_filtered, mod_0)
```
```{r predicted v actual}
plot_actual_v_predicted <- function(data, model){
  data %>% 
  ungroup() %>% 
  modelr::add_predictions(model) %>% 
  modelr::add_residuals(model) %>% 
  arrange(resid) %>% 
  group_by(yearid) %>% 
  mutate(rank = row_number(resid)) %>% 
  ggplot(aes(x = year_end, y = pred)) +
  geom_point(aes(color = cum_enrolled),
             size = .001) +
  scale_color_kipp(discrete = FALSE) +
  facet_grid(yearid ~.)
}

plot_actual_v_predicted(yca_filtered, mod_0)
```


### Logit
Let's fit these with a logit
```{r logit}
mod_1 <- glm(formula = formula_0,
             family = stats::binomial(link = "logit"),
             data = yca_filtered)

summary(mod_1)

#plot_ranked_residuals(yca_filtered, mod_1)
#plot_actual_v_residuals(yca_filtered, mod_1)

```
```{r}
yca_filtered %>% 
  ungroup() %>%
  modelr::add_predictions(mod_1) %>%
  modelr::add_residuals(mod_1) %>% 
  mutate(pred = exp(pred)/(1+exp(pred)))
```


## Model Evaulation 

We need to partition into train and test to better evaluate our models.  

We'll take [rsample](tidymodels.github.io/rsample) for a spin!

```{r rsample}
yca_split <- yca_filtered %>%
  rsample::initial_split(prop = .75)

yca_train <- analysis(yca_split)
yca_test <- assessment(yca_split)


mod_lm_train <- lm(formula = formula_0, data = yca_train)

yca_augmented <- broom::augment(mod_lm_train, 
                                newdata = yca_test) %>%
  mutate(resid = year_end - .fitted)

yca_augmented %>% 
  ggplot(aes(x = year_end, y = .fitted)) +
  geom_point(aes(color = cum_enrolled, size = -cum_enrolled)) +
  geom_abline(aes(intercept = 0, slope = 1)) +
  facet_grid(yearid~.) +
  scale_color_kipp(discrete = FALSE)

```
```{r size by se}
yca_augmented %>% 
  ggplot(aes(x = year_end, y = .fitted)) +
  geom_point(aes(color = cum_enrolled, size = .se.fit, shape = cum_absent>=16)) +
  geom_abline(aes(intercept = 0, slope = 1)) +
  facet_grid(yearid~.) +
  scale_color_kipp(discrete = FALSE)
```


```{r}
formula_0 <- as.formula(year_end ~ cum_enrolled + cum_absent + yearid)

mod_0 <- lm(formula = formula_0, 
            data = yca_filtered)

formulas <- list(
  as.formula(year_end ~ cum_enrolled + cum_absent),
  as.formula(year_end ~ cum_enrolled + cum_absent + yearid),
  as.formula(year_end ~ cum_enrolled + cum_absent + yearid + schoolid))

list_names <- formulas %>% 
  map_chr(deparse)

names(formulas) <- list_names

set.seed(1234)
rs_data <- vfold_cv(yca_filtered, v = 10, repeats = 3)

holdout_test <- function(splits, ...){
  model <- lm(..., 
              data = splits)
  
  holdout <- assessment(splits)
  
  res <- broom::augment(model, newdata = holdout)
  
  res
}

map_holdout <- function(data, formula){
  data$results <- map(data$splits,
                holdout_test,
                formula)
  
  data$mod_id <- as.character(deparse(formula))
  
  data

}

run_models <- formulas %>% 
  map(~{map_holdout(rs_data, .x) %>% 
      as_tibble()})

calc_rmse <- run_models %>% 
map_df(~mutate(.x, 
            rmse_0 = map2_dbl(results, 
                              results, 
                              ~rmse_vec(.x$year_end, 
                                        .y$.fitted))))


summarize_rmse <- calc_rmse %>% 
  group_by(mod_id) %>% 
  summarize(avg_rmse = mean(rmse_0))


summarize_rmse
```



```{r tobit two-way censored}
m_tobit <- vglm(year_end ~ cum_enrolled + cum_absent + yearid, tobit(Lower = 0, Upper = 1), data = yca_filtered)

formula_t <- formula(year_end ~ cum_enrolled + cum_absent + yearid)

summary(m_tobit)

holdout_tobit <- function(splits, ...){
  model_t <- vglm(..., 
                  tobit(Lower = 0, Upper = 1), 
                  data = splits)
  
  holdout <- assessment(splits)
  
  pred <- predict(object = model_t, newdata = holdout)
  
  holdout$.fitted <- pred[,1]
  holdout$.se <- pred[,2]
  
  holdout
}

map_holdout_tobit <- function(data, formula){
  data$results <- map(data$splits,
                holdout_tobit,
                formula)
  
  data$mod_id <- as.character(deparse(formula))
  
  data

}

run_models <- formulas %>% 
  map(~{map_holdout_tobit(rs_data, .x) %>% 
      as_tibble()})

calc_rmse <- run_models %>% 
map_df(~mutate(.x, 
            rmse_0 = map2_dbl(results, 
                              results, 
                              ~rmse_vec(.x$year_end, 
                                        .y$.fitted))))


summarize_rmse <- calc_rmse %>% 
  group_by(mod_id) %>% 
  summarize(avg_rmse = mean(rmse_0))


summarize_rmse

```

```{r holdout}

holdout_model_spec <- function(splits, model_type, formula, ...){
  if(tolower(model_type) == "linear"){
    model_spec <- linear_reg() %>% 
      set_engine("lm")
    model <- model_spec %>% 
      fit(formula, 
          data = as.data.frame(splits)) #parsnip wants df
  
  } 
  
  if(tolower(model_type) == "logistic"){
    model_spec <- parsnip::logistic_reg() %>%
      parsnip::set_engine("glm")
    model <- model_spec %>% 
      fit(formula,
          data = as.data.frame(splits))

  }
  
  ##Requires additional set of variables: mtry, ntrees
  # if(tolower(model_type) == "random_forest"){
  #   model_spec <- rand_forest() %>% 
  #     set_engine("rand_forest")
  #   model <- model_spec %>% 
  #     fit(..., 
  #         data = splits)
  # 
  # }
  
  if(tolower(model_type) == "knn") {
    model_spec <- nearest_neighbor(mode = "regression", ...) %>%
      set_engine("kknn")
    
    model <- model_spec %>%
      fit(formula, data = as.data.frame(splits))
  }
  holdout <- assessment(splits) 
  
  
  if(model_type == "knn") {
    predictions <- predict(model, new_data = holdout) #won't work with parsnip models
    res <- bind_cols(holdout, predictions) %>%
      rename(.fitted = .pred) %>%
      mutate(.se.fit = as.numeric(NA)) # can't seem to figure out this calcualtion KNN 
    
  args <- list(...)
  model_type <- sprintf("%s %s", model_type, args$neighbors)
  } else {
    res <- broom::augment(model$fit, newdata = holdout) #won't work with parsnip models
  }
  
  
  
  
  # Convert log-odds to probability measure 
  if(tolower(model_type) == "logistic") {
    res <- res %>% mutate(.fitted = exp(.fitted)/(1+exp(.fitted)))
  }
  
  res <- res %>% mutate(model = deparse(formula),
                 model_type = model_type)
  
  splits$results <- res
  
}


holdout_model_spec(rs_data$splits[[1]], "linear", formula_0) #works!
holdout_model_spec(rs_data$splits[[1]], "logistic", formula_0) 


x<-holdout_model_spec(rs_data$splits[[1]], "knn", formula_0, neighbors = 5)

x

```


## Cross-validated models {.tabset}
Let's do a bunch of parameterizations through Steph's `holdout_model_spec` function.  To do this we need a function that can take a `rsample` splits object and then a list of parameterizations. We'll do one model type (linear model, logistic, KNN) at a time.

The output should have the average RMSE for each model, as well as any other modeling output. 

```{r holdout_infrastructure, include = FALSE}

holdout_model_splits <- function(data, type, formula, ...){
  out <-data$splits %>% 
    map(holdout_model_spec, type, formula, ...) 

  out
  }

x<-holdout_model_splits(rs_data, "linear", formula_0)  

x$`1`
```
Okay, let's do three things: LM, logistic, and then KNN (with 3, 5, and 10 nearest neighbors):

### Linear Models
```{r lms}
x_lm <- formulas %>%
  map(~{holdout_model_splits(rs_data, "linear", .)})

x_lm_fit_summary <- x_lm %>% 
  map_df( . %>%
            map_df( . %>%  
                      summarize(rmse = rmse_vec(truth = year_end, estimate = .fitted), 
                                model =unique(model), 
                                model_type = unique(model_type)))
          ) 

```
### Logistic
```{r logistic, warning = FALSE}
x_logistic <- formulas %>%
  map(~{holdout_model_splits(rs_data, "logistic", .)})

x_logistic_fit_summary <- x_logistic %>% 
  map_df( . %>%
            map_df( . %>%  
                      summarize(rmse = rmse_vec(truth = year_end, estimate = .fitted), 
                                model =unique(model), 
                                model_type = unique(model_type)))
          ) 
```

### KNN

```{r}

# 3 neighbors
x_knn_3 <- formulas %>%
  map(~{holdout_model_splits(rs_data, "knn",  ., neighbors=3)})

x_knn_3_fit_summary <- x_knn_3 %>% 
  map_df( . %>%
            map_df( . %>%  
                      summarize(rmse = rmse_vec(truth = year_end, estimate = .fitted), 
                                model =unique(model), 
                                model_type = unique(model_type)))
          ) 

# 5 neighbors

x_knn_5 <- formulas %>%
  map(~{holdout_model_splits(rs_data, "knn",  ., neighbors=5)})

x_knn_5_fit_summary <- x_knn_5 %>% 
  map_df( . %>%
            map_df( . %>%  
                      summarize(rmse = rmse_vec(truth = year_end, estimate = .fitted), 
                                model =unique(model), 
                                model_type = unique(model_type)))
  )

# 10 neighbors
x_knn_10 <- formulas %>%
  map(~{holdout_model_splits(rs_data, "knn",  ., neighbors=10)})

x_knn_10_fit_summary <- x_knn_10 %>% 
  map_df( . %>%
            map_df( . %>%  
                      summarize(rmse = rmse_vec(truth = year_end, estimate = .fitted), 
                                model =unique(model), 
                                model_type = unique(model_type)))
  )

x_knn_fit_summary <- bind_rows(x_knn_3_fit_summary, x_knn_5_fit_summary, x_knn_10_fit_summary)
```

Now we bring all the `x_*_fit_summary` tables together and plot the results:

```{r plot fits}
x_fit_summary <- bind_rows(x_lm_fit_summary, 
                           x_logistic_fit_summary, 
                           x_knn_fit_summary)

x_fit_summary
```
## Plotting RMSE
```{r plot_avg_rmse}
x_fit_summary %>%
  group_by(model, model_type) %>%
  summarize(mean_rmse = mean(rmse)) %>%
  arrange(desc(mean_rmse)) %>%
  ungroup() %>%
  mutate(model = fct_inorder(model),
         model_type = fct_inorder(model_type)
         ) %>%

  ggplot() +
  geom_point(aes(x = model, y = mean_rmse, color= model_type), show.legend = FALSE) +
  geom_segment(aes(x = model,xend = model, y = mean_rmse, yend=0, color= model_type), show.legend = FALSE) +
  facet_grid(model_type ~ .) +
  coord_flip() + 
  scale_color_kipp() +
  labs(x = "Model",
       y = "Root Mean Squared Error")
```
```{r}
x_fit_summary %>%
  #group_by(model_type, model) %>%
arrange(rmse) %>%
  ungroup() %>%
  mutate(model = fct_inorder(model),
         model_type = fct_inorder(model_type)
         ) %>%
ggplot() +
  geom_violin(aes(y = rmse, 
                  x = model,
                  fill = model_type
                  ), show.legend = FALSE) +
  geom_point(data = x_fit_summary %>% 
               group_by(model, model_type) %>% 
               summarize(rmse = mean(rmse)), 
             aes(x = model, y = rmse), 
             show.legend = FALSE) +
  geom_linerange(data = x_fit_summary %>% 
               group_by(model, model_type) %>% 
               summarize(y_min = mean(rmse) - 1*sd(rmse), 
                         y_max = mean(rmse) + 1*sd(rmse)), 
             aes(x = model, ymin = y_min, ymax = y_max), 
             show.legend = FALSE) +
  facet_grid(model_type ~ .) +
  coord_flip() + 
  scale_fill_kipp()
  labs(x = "Model",
       y = "Root Mean Squared Error")

```

```{r}
x_fit_summary %>%
ggplot(aes(x=rmse)) +
  geom_density(aes(fill = model_type), show.legend = FALSE) +
  
   geom_segment(data = x_fit_summary %>% 
               group_by(model, model_type) %>% 
               summarize(x_min = mean(rmse) - 1*sd(rmse), 
                         x_max = mean(rmse) + 1*sd(rmse)), 
             aes(y = 0, yend=0, x = x_min, xend = x_max),
             size = 1.25,
             color = kipp_colors$darkgray,
             show.legend = FALSE) +
  
  geom_point(data = x_fit_summary %>% 
               group_by(model, model_type) %>% 
               summarize(rmse = mean(rmse)), 
             aes(x = rmse, y = 0), 
             show.legend = FALSE,
             shape = 21, 
             fill = "white",
             color = kipp_colors$darkgray) +
  
  facet_grid(model ~ model_type, switch = "y") + 
  scale_fill_kipp() +
  theme(strip.text.y = element_text(angle = 180),
        axis.text.x = element_text(angle = 45))  +
  labs(y = "Model",
       x = "Root Mean Squared Error")
  
```

## Bayesian Analysis

###Varying Intercepts: Greta

```{r varying intercept only}
yca_filtered_bayes <- yca_filtered %>% 
  mutate(schoolid_idx = as.integer(as.factor(schoolid)))
 
vi_cum_enroll <- as_data(yca_filtered_bayes$cum_enrolled)
vi_cum_absent <- as_data(yca_filtered_bayes$cum_absent)
vi_school_id <- as_data(yca_filtered_bayes$schoolid_idx)

vi_int <- greta::normal(0, 10)
vi_b_e <- greta::normal(0, 10)
vi_b_a <- greta::normal(0, 10)
vi_sd <- greta::cauchy(0, 3, truncation = c(0, Inf))

# random intercepts
vi_school_int_sd <- greta::lognormal(0, 1)
vi_school_int <- greta::normal(0, vi_school_int_sd, dim = 6)
vi_school_int_eff <- rbind(0, vi_school_int)


# model
vi_mu <- vi_int + vi_cum_enroll * vi_b_e + vi_cum_absent * vi_b_a + vi_school_int_eff[vi_school_id]

vi_y <- as_data(yca_filtered_bayes$year_end)

distribution(vi_y) <- greta::normal(vi_mu, vi_sd)

vi_m <- model(vi_int,
              vi_b_e,
              vi_b_a,
              vi_sd,
              vi_school_int_eff
  
)

plot(vi_m)

draws_vi <- greta::mcmc(vi_m, n_samples = 2000, n_cores = 4, chains = 4)

pred_test_vi <- greta::calculate(vi_mu, draws_vi)


```

```{r predicted year end varying intercept model}
pred_values_vi <- colMeans(rbind(pred_test_vi$`11`, pred_test_vi$`12`, pred_test_vi$`13`, pred_test_vi$`14`))

sqrt(mean((pred_values_vi - yca_filtered_bayes$year_end)^2))

sum(yca_filtered_bayes$year_end > .975)/ length(yca_filtered_bayes$year_end)

sum(pred_values_vi > .975)/ length(pred_values_vi)
```

```{r comparing year end to predicted}
ggplot() +
  geom_point(data = yca_filtered_bayes %>% 
               rowid_to_column("n"), aes(x = year_end, y = n)) +
  coord_flip()

pred_values_vi <- pred_values_vi %>% 
  as_tibble() %>% 
  rename(predicted = value)

orig_year_end <- yca_filtered_bayes$year_end %>% 
  as_tibble() %>% 
  rename(year_end = value)

bind_cols(orig_year_end, pred_values_vi) %>% 
  ggplot() +
  geom_point(aes(year_end, predicted)) +
  geom_abline(slope = 1, intercept = 0)
```

**Predicting 18-19 Attendance**
```{r, 18-19 new data}
new_yearly_ada <- student_att %>% 
  filter(yearid > 27) %>%
  group_by(yearid,
           studentid) %>% 
  summarize(enrolled = sum(enrolled),
            absent = sum(absent),
            year_end = 1 - (absent/enrolled))
 
new_cum_ada <- student_att %>% 
  filter(yearid > 27) %>%
  group_by(yearid,
           studentid) %>% 
  arrange(date) %>% 
  mutate(cum_enrolled = cumsum(enrolled),
         cum_absent = cumsum(absent),
         running_ada = 1 - (cum_absent/cum_enrolled)) %>% 
  filter(cum_enrolled > 0)

new_yearly_cum_ada <- new_cum_ada %>% 
  select(yearid,
         schoolid,
         grade_level,
         studentid,
         date,
         cum_enrolled,
         cum_absent,
         running_ada) %>% 
  dplyr::left_join(new_yearly_ada %>% 
              rename(yr_end_enrolled = enrolled, 
                     yr_end_absent = absent),
            by = c("yearid",
                   "studentid")) %>% 
  filter(yr_end_enrolled < 200,
         lubridate::month(date) == 12) %>% 
  filter(date == max(date)) %>% 
  mutate(cum_present = cum_enrolled - cum_absent) %>% 
  ungroup() 

new_data <-  new_yearly_cum_ada %>% 
  filter(!schoolid == 4001632) %>% 
  mutate(yr_end_present = 0,
         school_id = factor(schoolid, levels = c(7810, 78102, 400146, 400163, 400180, 4001802)),
         schoolid = factor(schoolid, levels = c(7810, 78102, 400146, 400163, 400180, 4001802))) %>%
  select(school_id,
         schoolid,
         yr_end_present,
         yr_end_enrolled,
         cum_present,
         cum_absent)

  
```

```{r}
new_data <-  new_yearly_cum_ada %>% 
  filter(!schoolid == 4001632) %>% 
  mutate(school_id = as.integer(as.factor(schoolid))) %>% 
  select(school_id,
         cum_enroll = cum_enrolled,
         cum_absent,
         year_end)

new_cum_enroll <- as_data(new_data$cum_enroll)
new_cum_absent <- as_data(new_data$cum_absent)
new_school_id <- as_data(new_data$school_id)

new_mu_vi <- vi_int + new_cum_enroll * vi_b_e + new_cum_absent * vi_b_a + vi_school_int_eff[new_school_id]

pred_new_data_vi <- greta::calculate(new_mu_vi, draws_vi)

vi_new_pred_values <- colMeans(rbind(pred_new_data_vi$`11`, pred_new_data_vi$`12`, pred_new_data_vi$`13`, pred_new_data_vi$`14`))

sqrt(mean((vi_new_pred_values - new_data$year_end)^2))

sum(new_data$year_end > .975)/ length(new_data$year_end)

sum(vi_new_pred_values > .975)/ length(vi_new_pred_values)
```


```{r}
vi_draws_coef <- colMeans(rbind(draws_vi$`11`, draws_vi$`12`, draws_vi$`13`, draws_vi$`14`))

#new_pred_values_vi[1976]

pred_student_ex <- new_data[1976,] %>% 
  mutate(predicted_yr_end = vi_new_pred_values[1976],
         sd_plus = predicted_yr_end + draws_vi_coef[4],
         sd_minus = predicted_yr_end - draws_vi_coef[4],
         dec_ada = 1 - (cum_absent/cum_enroll),
         month = "Jun")

```

```{r}
pred_student <- pred_student_ex %>% 
  tidyr::gather(key, value, -c(school_id:cum_absent, month)) %>% 
  mutate(month = if_else(grepl("dec", key), "Dec", month),
         month = factor(month, levels = c("Aug",
                                          "Sep",
                                          "Oct",
                                          "Nov",
                                          "Dec",
                                          "Jan",
                                          "Feb",
                                          "Mar",
                                          "Apr",
                                          "May",
                                          "Jun")),
         group_no = c("group_4", "group_3", "group_2", "group_1", "group_2")) 

pred_student %>%
  bind_rows(pred_student[5,] %>% 
            mutate(group_no = "group_1")) %>% 
ggplot() +
geom_point(aes(x = month, y = value)) +
geom_path(aes(y = value, x = month, group = group_no),) +
theme_kipp_light()
```


```{r}
ggplot() +
  geom_point(data = new_data %>% 
               rowid_to_column("n"), aes(x = year_end, y = n))

new_pred_values_ri <- new_pred_values_ri %>% 
  as_tibble() %>% 
  rename(predicted = value)

new_year_end <- new_data$year_end %>% 
  as_tibble() %>% 
  rename(year_end = value)

bind_cols(new_year_end, new_pred_values_ri) %>% 
  ggplot() +
  geom_point(aes(year_end, predicted)) +
  geom_abline(slope = 1, intercept = 0)
```

### Varying Slope and Intercept: Greta
$$ y_{i} = f(\alpha + \beta_{e}d_{e} + \beta_{a}d_{a} +
\alpha_{s[i]} + \beta_{e,s[i]}d_{e} + \beta_{a,s[i]}d_{a}) $$

A random slope model allows for each school line to have a different slope, meaning the predictors have a different effect for each school. 

```{r bayes setup varying slope and intercept}
rm(list=ls(pattern="vi_"))

cum_enroll <- as_data(yca_filtered_bayes$cum_enrolled)
cum_absent <- as_data(yca_filtered_bayes$cum_absent)
school_id <- as_data(yca_filtered_bayes$schoolid_idx)

int <- greta::normal(0, 10)
b_e <- greta::normal(0, 10)
b_a <- greta::normal(0, 10)
sd <- greta::cauchy(0, 3, truncation = c(0, Inf))

# random intercepts
school_int_sd <- greta::lognormal(0, 1)
school_int <- greta::normal(0, school_int_sd, dim = 6)
school_int_eff <- rbind(0, school_int)

# random slopes
school_slope_sd_e <- greta::lognormal(0, 1)
school_slope_sd_a <- greta::lognormal(0, 1)
school_slope_e <- greta::normal(0, school_slope_sd_e, dim = 6)
school_slope_a <- greta::normal(0, school_slope_sd_a, dim = 6)
school_slope_eff_e <- rbind(0, school_slope_e)
school_slope_eff_a <- rbind(0, school_slope_a)

# model
mu <- int + cum_enroll * b_e + cum_absent * b_a + school_int_eff[school_id] + cum_enroll * school_slope_eff_e[school_id] + cum_absent * school_slope_eff_a[school_id]

y <- as_data(yca_filtered_bayes$year_end)

distribution(y) <- greta::normal(mu, sd)

```

```{r bayes model varying slope and intercept}
m <- model(int,
           b_e,
           b_a,
           sd,
           school_int_eff,
           school_slope_eff_e,
           school_slope_eff_a)

plot(m)
```



```{r bayes mcmc draws varying slope and intercept}
draws <- greta::mcmc(m, n_samples = 2000, n_cores = 4, chains = 4)

draws_coef <- colMeans(rbind(draws$`11`, draws$`12`, draws$`13`, draws$`14`))

pred_test <- greta::calculate(mu, draws)

pred_values <- colMeans(rbind(pred_test$`11`, pred_test$`12`, pred_test$`13`, pred_test$`14`))

sqrt(mean((pred_values - yca_filtered_bayes$year_end)^2))

sum(yca_filtered_bayes$year_end > .975)/ length(yca_filtered_bayes$year_end)

sum(pred_values > .975)/ length(pred_values)

```


```{r}
ggplot() +
  geom_point(data = yca_filtered_bayes %>% 
               rowid_to_column("n"), aes(x = year_end, y = n))

pred_values <- pred_values %>% 
  as_tibble() %>% 
  rename(predicted = value)

orig_year_end <- yca_filtered_bayes$year_end %>% 
  as_tibble() %>% 
  rename(year_end = value)

bind_cols(orig_year_end, pred_values) %>% 
  ggplot() +
  geom_point(aes(year_end, predicted)) +
  geom_abline(slope = 1, intercept = 0)
  
```



```{r}
rm(list = c("new_mu_vi",
            "pred_new_data_vi"))

new_cum_enroll <- as_data(new_data$cum_enroll)
new_cum_absent <- as_data(new_data$cum_absent)
new_school_id <- as_data(new_data$school_id)

new_mu <- int + new_cum_enroll * b_e + new_cum_absent * b_a + school_int_eff[new_school_id] + new_cum_enroll * school_slope_eff_e[new_school_id] + new_cum_absent * school_slope_eff_a[new_school_id]

pred_new_data <- greta::calculate(new_mu, draws)

new_pred_values <- colMeans(rbind(pred_new_data$`11`, pred_new_data$`12`, pred_new_data$`13`, pred_new_data$`14`))

sqrt(mean((new_pred_values - new_data$year_end)^2))

sum(new_data$year_end > .975)/ length(new_data$year_end)

sum(new_pred_values > .975)/ length(new_pred_values)
```


```{r}
pred_student_vsi_ex <- new_data[1976,] %>% 
  mutate(predicted_yr_end = new_pred_values[1976],
         sd_plus = predicted_yr_end + draws_coef[4],
         sd_minus = predicted_yr_end - draws_coef[4],
         dec_ada = 1 - (cum_absent/cum_enroll),
         month = "Jun")

```

```{r}
pred_student_vsi <- pred_student_vsi_ex %>% 
  tidyr::gather(key, value, -c(school_id:cum_absent, month, sd_plus, sd_minus)) %>% 
  mutate(month = if_else(grepl("dec", key), "Dec", month),
         month = factor(month, levels = c("Aug",
                                          "Sep",
                                          "Oct",
                                          "Nov",
                                          "Dec",
                                          "Jan",
                                          "Feb",
                                          "Mar",
                                          "Apr",
                                          "May",
                                          "Jun"))) %>% 
  #filter(!grepl("year_end", key)) %>% 
  mutate(sd_minus = if_else(grepl("dec", key), value, sd_minus),
         sd_plus = if_else(grepl("dec", key), value, sd_plus))

pred_student_vsi %>%
filter(!grepl("year_end", key)) %>% 
  mutate(month = as.integer(month)) %>% 
ggplot(aes(x = month)) +
geom_ribbon(aes(ymin = sd_minus, ymax = sd_plus), color = "gray", alpha = .25, lty = 2)+
geom_line(aes(y = value, group = 1)) +
geom_point(data = pred_student_vsi %>% 
             mutate(month = as.integer(month)), 
           aes(y = value, x = month, color = key)) +
ggrepel::geom_text_repel(data = pred_student_vsi %>% 
          mutate(month = as.integer(month)),
          aes(y = value, x = month), 
          label = c("Actual",
                    "Prediction",
                    "Dec ADA"),
          ) +
scale_x_discrete(limits = c(5, 11),
                 labels = c("Dec", "Jun")) +
scale_color_manual(values = kipp_palettes$kipp_div) +
theme_kipp_light() +
theme(legend.position = "none")
```

```{r}
ggplot() +
  geom_point(data = new_data %>% 
               rowid_to_column("n"), aes(x = year_end, y = n))

new_pred_values <- new_pred_values %>% 
  as_tibble() %>% 
  rename(predicted = value)

new_year_end <- new_data$year_end %>% 
  as_tibble() %>% 
  rename(year_end = value)

bind_cols(new_year_end, new_pred_values) %>% 
  ggplot() +
  geom_point(aes(year_end, predicted)) +
  geom_abline(slope = 1, intercept = 0)
```

### Varying Intercept - Binomial Model
```{r}

```



```{r}
bayesplot::mcmc_trace(draws, pars = "int")
bayesplot::mcmc_intervals(draws)
mcmc_hist(draws, pars = "int")
mcmc_parcoord(draws)
```


```{r mcmc plots varying slope and intercept}
mcmc_trace(draws, facet_args = list(ncol = 3))
mcmc_intervals(draws)
mcmc_acf_bar(draws)
mcmc_hist(draws, facet_args = list(ncol = 3), binwidth = 10)
```


```{r bayes setup rstan model}
yca_filtered_bayes <- yca_filtered %>% 
  mutate(schoolid_idx = as.integer(as.factor(schoolid)),
         yr_end_present = as.integer(yr_end_present),
         yr_end_absent = as.integer(yr_end_absent),
         cum_present = as.integer(cum_present),
         cum_absent = as.integer(cum_absent))

yca_filtered_bayes_17_18 <-   yca_filtered_bayes %>% 
  filter(yearid == 27)
 
# yr_end_present <- yca_filtered_bayes$yr_end_present
# yr_end_absent <- yca_filtered_bayes$yr_end_absent
# school_id <- yca_filtered_bayes$schoolid_idx

SEED <- 1234
wi_prior <- normal(-1, 1)  # weakly informative prior on log-odds
# fit_pool <- stan_glmer(cbind(yr_end_present, yr_end_absent) ~ (1|school_id), data = yca_filtered_bayes, family = stats::binomial("logit"),
#                      prior_intercept = wi_prior, seed = SEED, iter = 100)

fit_pool <- stan_glmer(cbind(yr_end_present, yr_end_enrolled - yr_end_present) ~ (1|school_id) + cum_present + cum_absent, data = yca_filtered_bayes_17_18, family = stats::binomial("logit"),
                     prior = wi_prior,
                     prior_intercept = wi_prior, 
                     seed = SEED,
                     cores = 4)

fit_pool_all_years <- stan_glmer(cbind(yr_end_present, yr_end_enrolled - yr_end_present) ~ (1|schoolid) + cum_present + cum_absent, data = yca_filtered_bayes, family = stats::binomial("logit"),
                     prior = wi_prior,
                     prior_intercept = wi_prior, 
                     seed = SEED,
                     cores = 4)

fit_pool_vary_slope_2 <- stan_glmer(cbind(yr_end_present, yr_end_enrolled - yr_end_present) ~ cum_present + cum_absent + (1 + cum_present + cum_absent | schoolid), data = yca_filtered_bayes, family = stats::binomial("logit"),
                     prior = wi_prior,
                     prior_intercept = wi_prior, 
                     seed = SEED,
                     cores = 4,
                     iter = 100,
                     chains = 4)

fit_pool$coefficients
fit_pool_all_years$coefficients
fit_pool_vary_slope$coefficients 

```




```{r posterior predict}
ppd_18_19_ada <- posterior_predict(fit_pool, new_data)
ppd_18_19_ada_all <- posterior_predict(fit_pool_all_years, new_data)

#averaging the 4,000 draws per student observation
student_avg <- round(colMeans(ppd_18_19_ada))
student_avg_all <- round(colMeans(ppd_18_19_ada_all))

#actual year end days enrolled
days_enrolled <- new_data$yr_end_enrolled 

#actual year end days present
actual_days_present <- new_yearly_cum_ada %>% 
  filter(!schoolid == 4001632) %>% 
  mutate(yr_end_present = yr_end_enrolled - yr_end_absent) %>% 
  select(yr_end_present)

#posterior predicted days present/ days enrolled for ADA
student_ada <-  student_avg/ days_enrolled
student_ada_all <-  student_avg_all/ days_enrolled

#% students with predicted ADA > 97.5
sum(student_ada >= .975) / length(student_ada)
sum(student_ada_all >= .975) / length(student_ada_all)

#actual year end ADA
real_ada <- actual_days_present/days_enrolled

#% students with actual year end ADA > 97.5
sum(real_ada > .975) / nrow(real_ada)


#predicted and y[i] are pretty off, attempting to calc ADA % via coefficients
calc_ada <- function(data){
  data %>% 
    mutate(school_idx = as.numeric(as.factor(school_id)) + 3) %>% 
    mutate(ada = invlogit(fit_pool$coefficients["(Intercept)"] + (fit_pool$coefficients["cum_present"] * cum_present) + (fit_pool$coefficients["cum_absent"] * cum_absent) + fit_pool$coefficients[school_idx]))
}

calc_ada_all <- function(data){
  data %>% 
    mutate(school_idx = as.numeric(as.factor(school_id)) + 3) %>% 
    mutate(ada = invlogit(fit_pool_all_years$coefficients["(Intercept)"] + (fit_pool_all_years$coefficients["cum_present"] * cum_present) + (fit_pool_all_years$coefficients["cum_absent"] * cum_absent) + fit_pool_all_years$coefficients[school_idx]))
}

#higher % of students with predicted ADA >= 97.5, but it's just KOP and KOA students
new_data %>% 
  calc_ada() %>% 
  filter(ada > .975) #468/2288 JUST KOP AND KOA
#875/2288
new_data %>% 
  calc_ada() %>% 
  filter(ada > .95) #2000/2288

new_data %>% 
  calc_ada_all() %>% 
  filter(ada > .975) #468/2288 JUST KOP AND KOA
#875/2288
new_data %>% 
  calc_ada_all() %>% 
  filter(ada > .95) #2000/2288

#individual student ADA calculation for each of 4000 draws
ada_student_matrix <- matrix(nrow = 4000, ncol = 2288)
for(i in 1 : ncol(ppd_18_19_ada)){ 
     ada_student_matrix[,i] <- ppd_18_19_ada[, i] / days_enrolled[i]
}

#% of draws predicting >= 97.5 ADA
student_prop_97_5 <-NULL
for(i in 1 : ncol(ada_student_matrix)){ 
     student_prop_97_5[i] <- sum(ada_student_matrix[, i] >= .975)/ 4000
} 

#% of students with .5 prob of getting over 97.5 ADA
sum(student_prop_97_5 > .5) / length(student_prop_97_5)

```


**RSTAN Model Varying Intercept ~ Binomial**

```{r}
models <- "partial pooling"
estimates <- partialpool
colnames(estimates) <- c("lb", "median", "ub")
mean_ada <- yca_filtered_bayes %>% 
  group_by(schoolid_idx) %>% 
  summarize(sum_cum_present = sum(cum_present),
            sum_cum_enrolled = sum(cum_enrolled),
            mean_cum_ada = sum_cum_present/sum_cum_enrolled,
            sum_yr_present = sum(yr_end_present),
            sum_yr_enrolled = sum(yr_end_enrolled),
            mean_yr_ada = sum_yr_present/sum_yr_enrolled)

```


```{r}
print(fit_pool, digits = 3)
prior_summary(fit_pool)
summary(fit_pool, 
        pars = c("(Intercept)", "cum_present", "cum_absent", "b[(Intercept) school_id:1]","b[(Intercept) school_id:2]", "b[(Intercept) school_id:3]", "b[(Intercept) school_id:4]", "b[(Intercept) school_id:5]", "b[(Intercept) school_id:6]", "Sigma[school_id:(Intercept),(Intercept)]"),
        probs = c(0.025, 0.975),
        digits = 2)


sims <- as.matrix(fit_pool)
dim(sims)
para_name <- colnames(sims)

# Obtain school-level varying intercept a_j
# draws for overall mean
mu_a_sims <- as.matrix(fit_pool, 
                       pars = "(Intercept)")
# draws for 73 schools' school-level error
u_sims <- as.matrix(fit_pool, 
                    regex_pars = "b\\[\\(Intercept\\) school_id\\:")
# draws for 73 schools' varying intercepts               
a_sims <- as.numeric(mu_a_sims) + u_sims          

# Obtain sigma_y and sigma_alpha^2
# draws for sigma_y
s_pred_sims <- as.matrix(fit_pool, 
                       regex_pars = "cum_")
# draws for sigma_alpha^2
s_alpha_sims <- as.matrix(fit_pool, 
                       pars = "Sigma[school_id:(Intercept),(Intercept)]")


a_mean <- apply(X = a_sims,     # posterior mean
                MARGIN = 2,
                FUN = mean)
a_sd <- apply(X = a_sims,       # posterior SD
              MARGIN = 2,
              FUN = sd)

# Posterior median and 95% credible interval
a_quant <- apply(X = a_sims, 
                 MARGIN = 2, 
                 FUN = quantile, 
                 probs = c(0.025, 0.50, 0.975))
a_quant <- data.frame(t(a_quant))
names(a_quant) <- c("Q2.5", "Q50", "Q97.5")

# Combine summary statistics of posterior simulation draws
a_df <- data.frame(a_mean, a_sd, a_quant)
round(head(a_df), 2)


# Sort dataframe containing an estimated alpha's mean and sd for every school
a_df <- a_df[order(a_df$a_mean), ]
a_df$a_rank <- c(1 : dim(a_df)[1])  # a vector of school rank 

schoolid_no <- tribble(~"school", ~ "schoolid_no",
                       "KAMS", "school_id:1",
                       "KAP", "school_id:2",
                       "KAC", "school_id:3",
                       "KBCP", "school_id:4",
                       "KOA", "school_id:5",
                       "KOP", "school_id:6")
a_df <- a_df %>% 
  mutate(schoolid = rownames(a_df),
         schoolid_1 = str_extract(schoolid, "school_id:\\d")) %>% 
  left_join(schoolid_no,
            by = c("schoolid_1" = "schoolid_no"))
# Plot school-level alphas's posterior mean and 95% credible interval
ggplot(data = a_df, 
       aes(x = a_rank, 
           y = a_mean)) +
  geom_pointrange(aes(ymin = Q2.5, 
                      ymax = Q97.5),
                  position = position_jitter(width = 0.1, 
                                             height = 0)) + 
  geom_hline(yintercept = mean(a_df$a_mean), 
             size = 0.5, 
             col = "red") + 
  geom_text(aes(label = school)) +
  scale_x_continuous("Rank") + 
  scale_y_continuous(expression(paste("varying intercept, ", alpha[j]))) + 
  theme_bw( base_family = "serif")
```

```{r}
plot(fit_pool, prob = .95, prob_outer = 1) + geom_vline(xintercept = 0)

coef(fit_pool)
round(posterior_interval(fit_pool, prob = 0.9), 2)
```


```{r}
library(loo)
loo1 <- loo(fit_pool, save_psis = TRUE,
            cores = 4)

```


## Appendix 

### Packages and settings
```{r packages_append, ref.label='packages', echo=TRUE, results='markup'}

```
```{r knitr_append, ref.label='knitr_options', echo=TRUE, results='markup'}

```

### Getting data
Here we grab basic attendances and enrollment data from Silo (our warehouse):




```{r att_mem_tables_append, ref.label='att_mem_tables', echo=TRUE, results='markup'}

```

Now we join our daily membership and attendance tables and do some pre-processing. 
```{r joining_append, ref.label='joining_tables', echo=TRUE, results='markup'}

```

Recoding enrollment and attendance data:
```{r recoding_append, ref.label='recoding', echo=TRUE, results='markup'}
```

Getting student data:
```{r student_append, ref.label="students"}

```

